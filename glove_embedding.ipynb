{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import pos_tag ,pos_tag_sents\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove.twitter.27B.50d.txt', 'r' ,encoding='UTF-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        emb =np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18667 ,  0.21368 ,  0.14993 , -0.43155 , -0.33975 ,  0.8475  ,\n",
       "        0.38977 , -0.13955 , -0.46976 , -0.54834 ,  0.44025 ,  0.069026,\n",
       "       -6.1569  , -0.5549  ,  0.062301, -0.55152 ,  0.41341 ,  0.62345 ,\n",
       "       -0.37125 ,  0.3274  ,  0.18377 ,  0.18605 , -0.26863 ,  0.96635 ,\n",
       "        1.1219  ,  0.7215  ,  0.09091 , -0.64006 , -0.19457 , -0.47882 ,\n",
       "       -0.32703 ,  0.43049 , -0.24094 , -1.2938  ,  0.77391 , -0.26059 ,\n",
       "       -0.42837 ,  0.21792 , -0.014106, -0.49876 , -1.117   , -0.89154 ,\n",
       "       -0.09197 ,  0.28358 , -0.02093 , -0.61461 ,  0.45838 , -0.11498 ,\n",
       "       -0.24608 , -0.19549 ], dtype=float32)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_link(content):\n",
    "    '''remove links (using map) and hashtags and mentions'''\n",
    "    a = content[:content.find('http' or 'https')]\n",
    "    a = re.sub('#\\w+', '', a)\n",
    "    a = re.sub('@\\w+','',a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    '''lemmatize,tokenize,lower'''\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.token = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t).lower() for t in self.token.tokenize(articles) if t.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619950566786113536</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619969366986235905</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>619971047195045888</td>\n",
       "      <td>negative</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>619974445185302528</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>619987808317407232</td>\n",
       "      <td>positive</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     label  \\\n",
       "0  619950566786113536   neutral   \n",
       "1  619969366986235905   neutral   \n",
       "2  619971047195045888  negative   \n",
       "3  619974445185302528   neutral   \n",
       "4  619987808317407232  positive   \n",
       "\n",
       "                                             content  \n",
       "0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...  \n",
       "1  Order Go Set a Watchman in store or through ou...  \n",
       "2  If these runway renovations at the airport pre...  \n",
       "3  If you could ask an onstage interview question...  \n",
       "4  A portion of book sales from our Harper Lee/Go...  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SemEval2017-task4-dev.subtask-A.english.INPUT.txt', names = ['id', 'label', 'content'], sep ='\\t', index_col=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.content = data.content.map(remove_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize each content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = LemmaTokenizer()\n",
    "data['token'] = data.content.map(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619950566786113536</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "      <td>[picturehouse, pink, floyd, roger, waters, wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619969366986235905</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "      <td>[order, go, set, watchman, store, website, tue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>619971047195045888</td>\n",
       "      <td>negative</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "      <td>[runway, renovation, airport, prevent, seeing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>619974445185302528</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "      <td>[could, ask, onstage, interview, question, mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>619987808317407232</td>\n",
       "      <td>positive</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "      <td>[portion, book, sale, harper, lee, go, set, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     label  \\\n",
       "0  619950566786113536   neutral   \n",
       "1  619969366986235905   neutral   \n",
       "2  619971047195045888  negative   \n",
       "3  619974445185302528   neutral   \n",
       "4  619987808317407232  positive   \n",
       "\n",
       "                                             content  \\\n",
       "0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...   \n",
       "1  Order Go Set a Watchman in store or through ou...   \n",
       "2  If these runway renovations at the airport pre...   \n",
       "3  If you could ask an onstage interview question...   \n",
       "4  A portion of book sales from our Harper Lee/Go...   \n",
       "\n",
       "                                               token  \n",
       "0  [picturehouse, pink, floyd, roger, waters, wal...  \n",
       "1  [order, go, set, watchman, store, website, tue...  \n",
       "2  [runway, renovation, airport, prevent, seeing,...  \n",
       "3  [could, ask, onstage, interview, question, mis...  \n",
       "4  [portion, book, sale, harper, lee, go, set, wa...  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder(x):\n",
    "    '''embed each token with glove (if it exists in DS), also make the vector size 20'''\n",
    "    t =[]\n",
    "    for y in x:\n",
    "        try:\n",
    "            t.append(embeddings_dict[y])\n",
    "        except:\n",
    "            pass\n",
    "    while len(t)<20:\n",
    "        t.append([0]*50)\n",
    "    \n",
    "    return np.array(t[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of unique words count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index= []\n",
    "for token in data.token:\n",
    "    for t in token:\n",
    "        word_index.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224552"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20665"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vector']=data.token.map(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>token</th>\n",
       "      <th>vector</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619950566786113536</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "      <td>[picturehouse, pink, floyd, roger, waters, wal...</td>\n",
       "      <td>[[0.16812999546527863, 0.2084600031375885, 0.3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619969366986235905</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "      <td>[order, go, set, watchman, store, website, tue...</td>\n",
       "      <td>[[-0.5772899985313416, -0.24309000372886658, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>619971047195045888</td>\n",
       "      <td>negative</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "      <td>[runway, renovation, airport, prevent, seeing,...</td>\n",
       "      <td>[[-1.4539999961853027, -0.14899000525474548, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>619974445185302528</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "      <td>[could, ask, onstage, interview, question, mis...</td>\n",
       "      <td>[[0.01691400073468685, 0.480679988861084, -0.3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>619987808317407232</td>\n",
       "      <td>positive</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "      <td>[portion, book, sale, harper, lee, go, set, wa...</td>\n",
       "      <td>[[-0.07840699702501297, -0.4659999907016754, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     label  \\\n",
       "0  619950566786113536   neutral   \n",
       "1  619969366986235905   neutral   \n",
       "2  619971047195045888  negative   \n",
       "3  619974445185302528   neutral   \n",
       "4  619987808317407232  positive   \n",
       "\n",
       "                                             content  \\\n",
       "0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...   \n",
       "1  Order Go Set a Watchman in store or through ou...   \n",
       "2  If these runway renovations at the airport pre...   \n",
       "3  If you could ask an onstage interview question...   \n",
       "4  A portion of book sales from our Harper Lee/Go...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [picturehouse, pink, floyd, roger, waters, wal...   \n",
       "1  [order, go, set, watchman, store, website, tue...   \n",
       "2  [runway, renovation, airport, prevent, seeing,...   \n",
       "3  [could, ask, onstage, interview, question, mis...   \n",
       "4  [portion, book, sale, harper, lee, go, set, wa...   \n",
       "\n",
       "                                              vector  encoded_label  \n",
       "0  [[0.16812999546527863, 0.2084600031375885, 0.3...              1  \n",
       "1  [[-0.5772899985313416, -0.24309000372886658, -...              1  \n",
       "2  [[-1.4539999961853027, -0.14899000525474548, 0...              0  \n",
       "3  [[0.01691400073468685, 0.480679988861084, -0.3...              1  \n",
       "4  [[-0.07840699702501297, -0.4659999907016754, 0...              2  "
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in data.vector:\n",
    "    X.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20632, 20, 50)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train split and embedding labeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['encoded_label'] = le.fit_transform(data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, data.encoded_label.values, test_size=0.3, random_state=100)\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14442, 20, 50)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now added LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_47 (LSTM)               (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 29,635\n",
      "Trainable params: 29,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input\n",
    "model=Sequential()\n",
    "model.add(Input(shape=[20,50]))\n",
    "model.add(LSTM(64)) # model.add(LSTM(64,return_sequences=True))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'],learning_rate= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14314 samples, validate on 128 samples\n",
      "Epoch 1/6\n",
      "14314/14314 [==============================] - 11s 768us/sample - loss: 0.9098 - accuracy: 0.5582 - val_loss: 0.7636 - val_accuracy: 0.6719\n",
      "Epoch 2/6\n",
      "14314/14314 [==============================] - 7s 467us/sample - loss: 0.8111 - accuracy: 0.6251 - val_loss: 0.6994 - val_accuracy: 0.6875\n",
      "Epoch 3/6\n",
      "14314/14314 [==============================] - 6s 441us/sample - loss: 0.7838 - accuracy: 0.6407 - val_loss: 0.6968 - val_accuracy: 0.7188\n",
      "Epoch 4/6\n",
      "14314/14314 [==============================] - 6s 440us/sample - loss: 0.7732 - accuracy: 0.6462 - val_loss: 0.6744 - val_accuracy: 0.7109\n",
      "Epoch 5/6\n",
      "14314/14314 [==============================] - 6s 443us/sample - loss: 0.7511 - accuracy: 0.6572 - val_loss: 0.6562 - val_accuracy: 0.7109\n",
      "Epoch 6/6\n",
      "14314/14314 [==============================] - 6s 446us/sample - loss: 0.7374 - accuracy: 0.6682 - val_loss: 0.6372 - val_accuracy: 0.7031\n",
      "Test accuracy: 0.64442647\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6\n",
    "\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_token = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in data.token:\n",
    "    main_token.append(t.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(main_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gensim.models.Word2Vec(main_token, min_count = 1, size = 100, window = 10, sg = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_embedder(x):\n",
    "    '''embed each token with glove (if it exists in DS), also make the vector size 20'''\n",
    "    t =[]\n",
    "    for y in x:\n",
    "        try:\n",
    "            t.append(model2[y])\n",
    "        except:\n",
    "            pass\n",
    "    while len(t)<20:\n",
    "        t.append([0]*100)\n",
    "    \n",
    "    return np.array(t[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\98914\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data['vector']=data.token.map(w2v_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 100)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
